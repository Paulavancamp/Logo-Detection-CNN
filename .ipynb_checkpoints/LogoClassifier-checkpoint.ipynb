{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beverage Logo Classifier:\n",
    "\n",
    "- Program description:\n",
    "    - This program uses a dataset that I created on my own with images taken on my phone. I used the square filter on the camera to ensure all images are reducable to 40x40 pixels without extra cropping. The training set has 100+ images of beverage bottles/cans belonging to 5 different brands (at least 20 of each). The test set has an additional 25+ pictures (at least 5 of each).\n",
    "        1. Starbucks energy drink (can)\n",
    "        2. Monster energy (can)\n",
    "        3. Silk milk  (carton)\n",
    "        4. Bon & Viv (can)\n",
    "        5. Pure Leaf tea (bottle)\n",
    "\n",
    "\n",
    "- Tools and methods\n",
    "    - I use pillow to process all the images. Their starting size in the 'raw' folder is 320x320 pixels.  I scale them down by a factor of 10 and convert each to PNG format. The new images are all stored in a thumbnail folder to use for the rest of the program. \n",
    "    - To covert to arrays I read the files back in and stored all of their data in an array used matplotlip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "this program makes use of matplotlib, pillow, and numpy to import and format all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "import PIL\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and Show single image\n",
    "\n",
    "An image is opened with matplotlib.  It is displayed on the screen to show an example of the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "data = image.imread('rawtrainimages/mon26.jpg')\n",
    "# summarize shape of the pixel array\n",
    "print(data.dtype)\n",
    "print(data.shape)\n",
    "# display the array of pixels as an image\n",
    "pyplot.imshow(data)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize All images to 32x32 thumbnail\n",
    "\n",
    "both the training and test sets are reformatted to a thumbnail verison of the original picture.  I did not want to overwrite the original images, so the thumbnails are stored in a separate file starting with \"new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "from os import listdir #This method returns a list containing the names of the entries in the directory given by path.\n",
    "\n",
    "size = 40, 40\n",
    "\n",
    "##Testing Data\n",
    "loaded_images = list()\n",
    "for filename in listdir('rawtestimages'): #loop through all internet images\n",
    "    image = Image.open('rawtestimages/' + filename) #get the original internet file\n",
    "    image = image.convert('RGB') #switch out of RGBA mode\n",
    "    image.thumbnail(size)\n",
    "    image.save('testthumbnails/'+filename + \".PNG\", \"PNG\")  \n",
    "    cropped = Image.open('testthumbnails/'+filename + \".PNG\")\n",
    "    print(cropped.size)\n",
    "    \n",
    "## TRAINING DATA\n",
    "loaded_images = list()\n",
    "for filename in listdir('rawtrainimages'): #loop through all internet images\n",
    "    image = Image.open('rawtrainimages/' + filename) #get the original internet file\n",
    "    image = image.convert('RGB') #switch out of RGBA mode\n",
    "    image.thumbnail(size)\n",
    "    image.save('trainthumbnails/'+filename + \".PNG\", \"PNG\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data sets\n",
    " \n",
    "Both X and Y data sets are created within these sections.  All test images (that are appropriately sized) are read into a list and their category is stored in a separate list.  The name of the file is used to categorize the image.  For example, all starbucks products are named sb#, so if it contians sb it belongs to category 1. By using the same loop, the file and category indecies should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "test_images = list() #create empty list\n",
    "test_data = list()\n",
    "for filename in listdir('testthumbnails'): #run loop of all images to store in list\n",
    "    img_data = image.imread('testthumbnails/' + filename) # load image using matplotlib\n",
    "    test_images.append(img_data) # store loaded image\n",
    "    print('> loaded %s %s' % (filename, img_data.shape)) #print to confirm \n",
    "    #add classifier to the y-data\n",
    "    if \"sb\" in filename:\n",
    "        test_data.append(1)\n",
    "    elif \"mon\" in filename:\n",
    "        test_data.append(2)\n",
    "    elif \"silk\" in filename:\n",
    "        test_data.append(3)\n",
    "    elif \"bv\" in filename:\n",
    "        test_data.append(4)\n",
    "    elif \"pl\" in filename:\n",
    "        test_data.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "train_images = list() #create empty list\n",
    "train_data = list()\n",
    "for filename in listdir('trainthumbnails'): \n",
    "    #store image data in list (x)\n",
    "    img_data = image.imread('trainthumbnails/' + filename) # load image using matplotlib\n",
    "    train_images.append(img_data) # store loaded image\n",
    "    print('> loaded %s %s' % (filename, img_data.shape)) #print to confirm \n",
    "    \n",
    "    #add classifier value based on name (y)\n",
    "    if \"sb\" in filename:\n",
    "        train_data.append(1)\n",
    "    elif \"mon\" in filename:\n",
    "        train_data.append(2)\n",
    "    elif \"silk\" in filename:\n",
    "        train_data.append(3)\n",
    "    elif \"bv\" in filename:\n",
    "        train_data.append(4)\n",
    "    elif \"pl\" in filename:\n",
    "        train_data.append(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data set \n",
    "\n",
    "All the data needs to be in numpy arrays for the rest of the program to run through the model\n",
    "- x_train (the variable that contains the images to train on)\n",
    "- y_train (the variable that contains the labels of the images in the training set)\n",
    "- x_test (the variable that contains the images to test on), \n",
    "- y_test (the variable that contains the labels of the images in the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#load data into sets for creating the model\n",
    "x_train = np.array(train_images)\n",
    "y_train = np.array(train_data)\n",
    "x_test = np.array(test_images)\n",
    "y_test = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the shape \n",
    "\n",
    "- The shape of the x_train data set is a 4-Dimensional array with 100 rows of 32 x 32 pixel image with depth = 3 (RGB)\n",
    "- The y_train data shape is a 2-Dimensional array with 100 rows and 1 column. \n",
    "- The shape of the x_test data set is a 4-Dimensional array with 25 rows of 32 x 32 pixel image with depth = 3 (RGB). \n",
    "- The y_test data shape is a 2-Dimensional array with 25 rows and 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the shape of x_train\n",
    "print('x_train shape:', x_train.shape)\n",
    "#Get the shape of y_train\n",
    "print('y_train shape:', y_train.shape)\n",
    "#Get the shape of x_train\n",
    "print('x_test shape:', x_test.shape)\n",
    "#Get the shape of y_train\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize sample Data\n",
    "\n",
    "The following sections take a look at the first image (at index=0) in the training data set as a numpy array. \n",
    "\n",
    "First, it is shown as an array of of pixel values, then it is shown in the image form along with it's label.\n",
    "\n",
    "There are 5 categories so the label represent the specific category within the 5 types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show reformated image\n",
    "\n",
    "The same image from before is displayed again to show the changes in format and the label is printed to confirm the y-data was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imageVal = 38\n",
    "img = plt.imshow(x_train[imageVal])\n",
    "print('The label is:', y_train[imageVal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Data\n",
    "\n",
    "First, we use One-Hot Encoding to convert the labels into a set of 10 numbers to input into the neural network. \n",
    "The numbers of course corresponds with the number of labels to classify the images.\n",
    "\n",
    "Then, the pixels are normalized to be either 0 or 1 instead of a value between 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# One hot\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "print(y_train_one_hot)\n",
    "\n",
    "# normalize colors which are 0-255 to 0.0-1.0\n",
    "X_train = x_train.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "X_test = x_test.astype('float32')\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n",
    "# encode outputs for manipulation by encoding into a binary matrix\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the CNN\n",
    "\n",
    "To build the model we need to create the architecture using Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Building the CNN\n",
    "The CNN is built through a series of 19 steps.  These include a mixture of convolutional, dropout, and max pooling layers which are flattened and run through neural networks to define the structure. \n",
    "\n",
    "\n",
    "Convolutional layer: \n",
    "    - We add the first layer, a convolution layer to extract features from the input image, and create 32, 5 x 5 ReLu convoluted features also known as feature maps. \n",
    "    - For the first layer we must input the dimension shape which is a 64 x 64 pixel image with depth = 3 (RGB). \n",
    "    - All other layers do not have an input parameter\n",
    "\n",
    "Dropout:\n",
    "     - This is a technique where randomly selected neurons are ignored during training.\n",
    "     - The effect is that the network becomes less sensitive to the specific weights of neurons\n",
    "\n",
    "Max Pooling Layer: \n",
    "    - Add the  pooling layer with a 2 x 2 pixel filter to get the max element from the feature maps. \n",
    "    - This reduces the dimension of the feature maps by half and is also known as sub sampling.\n",
    "\n",
    "Flattening layer:\n",
    "    - Used to reduce the image to a linear array also known as a one 1-Dimension vector\n",
    "    - Vector feeds into and connects with the neural network\n",
    "    \n",
    "Neural Network (dense):\n",
    "    - NN with first layer of 1024 neurons and the activation function ReLu\n",
    "    - Second has 512 and final has just 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(40, 40, 3), activation='relu', padding='same'))\n",
    "\n",
    "#2. Dropout Layer at 20%\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "#3. Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#4. Max Pool layer with size 2×2.\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#5. Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#6. Dropout layer at 20%.\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "#7. Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#8. Max Pool layer with size 2×2.\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#9. Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#10. Dropout layer at 20%\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "#11. Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#12. Max Pool layer with size 2×2.\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#13. Flatten layer.\n",
    "model.add(Flatten())\n",
    "\n",
    "#14. Dropout layer at 20%\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#15. Fully connected layer with 1,024 units and a rectifier activation function\n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\n",
    "#16. Dropout layer at 20%\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "#17. Fully connected layer with 512 units and a rectifier activation function\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\n",
    "#18. Dropout layer at 20%\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "#19. Fully connected output layer with 10 units and a softmax activation function\n",
    "model.add(Dense(y_test.shape[1], activation='softmax')) #19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the CNN\n",
    "\n",
    "Finally, the model is compiled.  Give it the categorical_crossentropy loss function which is used for classes greater than 2, the adam optimizer, and the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "epochs = 75\n",
    "lrate = 0.03\n",
    "\n",
    "#set decay to lrate over epochs\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#print modle summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using the fit() method, which is another word for train. \n",
    "#We will train the model on the training data with batch size =256, epochs =10, and split the data into training on 70% of the data and using the other 30% as validation. Training may take some time to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the model's accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test_one_hot)[1]\n",
    "print(\"Accuracy: \")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the model's accuracy for both the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(hist.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the models loss for both the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the models loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Creation and CNN Test\n",
    "\n",
    "I created a GUI to understand how CNNs can be used after they are generated and optimized.  My GUI contains a window with a text entry for typing a file name (assumed to be in the same working directory) and a button to run the program.  The function that is called will locate the file, transform it into the right format, and then run it through to predict the logo\n",
    "\n",
    "Because I hard-coded the GUI to search within the directory named GUIimages, there are only a few images you can type in for now. including \"mon4.jpg\" \"bv8.jpg\" and \"silk3.jpg\"\n",
    "\n",
    "- Note: I've experienced some bugs when opening the GUI for the first time.  The last segment may need to be tried twice to get the display correct. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import image\n",
    "from PIL import Image \n",
    "from tkinter import *\n",
    "window=Tk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##All elements go here\n",
    "class MyWindow:\n",
    "    def __init__(self, win):\n",
    "        #label and text entry for file input\n",
    "        self.lbl1=Label(win, text='File Name')\n",
    "        self.lbl1.place(x=100, y=50)\n",
    "        self.t1=Entry(bd=3)\n",
    "        self.t1.place(x=200, y=50)\n",
    "        \n",
    "        #submit button to run program\n",
    "        self.btn1 = Button(win, text='file name')\n",
    "        self.b1=Button(win, text='Run CNN', command=self.run)\n",
    "        self.b1.place(x=100, y=150)\n",
    "        \n",
    "        #Label and entry for result\n",
    "        self.lbl2=Label(win, text='Result')\n",
    "        self.lbl2.place(x=100, y=200)\n",
    "        self.t2=Entry()\n",
    "        self.t2.place(x=200, y=200)    \n",
    "        \n",
    "    def run(self):\n",
    "        self.t2.delete(0, 'end')\n",
    "        #get the image name from input\n",
    "        inputimage = self.t1.get()\n",
    "        \n",
    "        #locate the image and reformat to PNG of size 32x32\n",
    "        from PIL import Image \n",
    "        image = Image.open('GUIimages/' + inputimage) #get the original internet file\n",
    "        image = image.convert('RGB') #switch out of RGBA mode\n",
    "        image.thumbnail(size) #resize to 32x32\n",
    "        image.save('GUIimages/'+inputimage + \".PNG\", \"PNG\") \n",
    "       \n",
    "        from matplotlib import image\n",
    "        img_data = image.imread('GUIimages/' + inputimage+ \".PNG\") # load image using matplotlib\n",
    "        X = img_data.astype('float32')\n",
    "        X = X / 255.0\n",
    "        img = np.expand_dims(X, axis=0)\n",
    "        \n",
    "        #run the image through the mdoel\n",
    "        print(model.predict(img))\n",
    "        prediction = model.predict(img)\n",
    "\n",
    "        #find maximum prediction value\n",
    "        maxElement = np.amax(prediction)\n",
    "        index = np.where(prediction == maxElement)\n",
    "        print(index)\n",
    "         \n",
    "        #set result\n",
    "        if index[0]==0:\n",
    "            result = 'Starbucks'\n",
    "        elif index[0]==1:\n",
    "            result = 'Monster'\n",
    "        elif index[0]==2:\n",
    "            result = 'Silk'\n",
    "        elif index[0]==2:\n",
    "            result = 'Bon & Viv'\n",
    "        else:\n",
    "            result = 'Pure Leaf'\n",
    "        \n",
    "        self.t2.insert(END, str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run and display window\n",
    "window=Tk()\n",
    "mywin=MyWindow(window)\n",
    "window.title('Logo Classifier CNN')\n",
    "window.geometry(\"400x300+10+10\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The model did not perform with high accuracy, as seen in the graphs, due to   this is due to the extremely small sample size of images.  Normal data sets will have several thousand images for each category but I made this on my own with 25 of each category.  For the purposes of this project, the accuracy is less important than the implementation and method. I've learned a lot about manipulating images and creating CNNs, so I could improve this in the future knowing what I now know. For example, by adding several more pictures of the Monster Energy cans and increasing picture resolution to 40x40 (instead of 32x32) I was able to improve the accuracy by 6%. With additional photos the model could develop more accurate mappings of the logos and increase accuracy further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Applications\n",
    "\n",
    "I decided to use logos for my CNN with the recycling industry in mind.  I could immagine a camera set up over the conveyor belts to scan for the patterns developed by the model and track the quantity of various products as they come in.  Companies will pay large amounts of money to receive data and it could help them to see where their products end up.  Companies could contribute to a large dataset with images of their products for the model to learn.  Then, within material recovery facilities, the products would pass through and a program would count as they are seen.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
